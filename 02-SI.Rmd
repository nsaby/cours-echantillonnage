Echantillonnage aléatoire simple {#SI}
=================================

Définition
-----------
Les unités sont sélectionnées avec une probabilité égale et indépendamment les unes des autres ; également appelé "échantillonnage aléatoire indépendant (IRS)"

- Deux sous-types :

+ avec remise (SIR)
+ sans remise (SI)

- Cette distinction n'est pas pertinente pour des populations infinies
- Toutes les combinaisons de $n$ unités de population (tous les échantillons de $n$ unités) ont une probabilité égale d'être sélectionnés

Mise en oeuvre avec un logiciel
------------------------------

### Pour les polutations discrètes
#### Excel 

Voici la procédure:

1. Utiliser la fonction ALEA dans une colonne ajouter au tableau des coordonnées à choisir
2. Copier coller en valeur le résultat de la fonction ALEA dans une nouvelle colonne
3. Classer le tableau par ordre croissant  selon la colonne créée à l'étape 2
4. Choisir les n premiers points du tableau


#### Avec `R` 

Voici comment tirer au hasard des positions dans l'espace à partir de la liste des pixels. 

```{r}
n = 20

#fixer la graine pour les tirages aléatoires
set.seed(5602)

# Creation des identifiants des lignes
id = 1:10000
# ou
id = seq( from = 1, to = 10000, by = 1)
# tire au hasard n valeurs parmi 10000
MesIds <- sample( x = id  , size = n)

MesIds <- sort(MesIds)
# Les coordonn?es
champ[ MesIds , 1:2 ]

```


Il est possible alors d'extraire les valeurs de carbone simulée pour les pixels tirés au hasard

```{r}
terrain1 <- champ[ MesIds, "sim1" ]
terrain1
```




### Avec `R` pour les populations continues

1 Déterminer les coordonnées minimales et maximales s1 et s2
du domaine (boîte englobante)

2 Tirez deux coordonnées (pseudo-)aléatoires indépendantes $s_{1,v}$ 
et $s_{2,aleat}$ 

3. Utilisez une routine de point dans le polygone pour déterminer si ($s_{1,v}$,$s_{2,aleat}$) tombe dans la zone

4. Répétez les étapes 2 et 3 jusqu'à ce que n positions soient sélectionnées



Le package `sp` offre la fonction `spsample` pour effectuer cette procédure à partir de couches SIG.


```{r SIsample, fig.cap='Exemple d\'échantillonnage aléatoire simple, avec 20 points SI(20)', out.width='110%', fig.asp=.75, fig.align='center'}
MonEch <- spsample( x = champSP ,
                    n  = n ,
                    type = "random")


SI <- tm_shape(champSP) +
  tm_raster()+
  tm_shape(MonEch)+
  tm_symbols()+
tm_layout(legend.outside = TRUE)

SI
```


Le package `sf` qui va remplacer progressivement `sp` contient la fonction `st_sample`.


```{r SIsampleSF, fig.cap='Exemple d\'échantillonnage aléatoire simple, avec 20 points SI(20), avec le package sf', out.width='110%', fig.asp=.75, fig.align='center'}
MonEchSF <- st_sample( x = as(champSP,'sf') ,
                    size  = n ,
                    type = "random")


SI <- tm_shape(champSP) +
  tm_raster()+
  tm_shape(MonEchSF)+
  tm_symbols()+
tm_layout(legend.outside = TRUE)

SI
```


Calcul des estimateurs
-----------------------

Dans cette partie nous explorons les techniques pour calculer les estimateurs des paramètres statistiques à partir des données collectées.


### l'estimateur de Horvitz-Thompson

L'estimateur H-T du total est $\hat t = \sum{z_i/\pi_i}$

L'estimateur H-T de la moyenne est $\hat{\overline{t} } = 1/N\sum_{i=1}^n{z_i/\pi_i}$

$\pi$ est la probabilité  qu'un site d'échantillonnage soit inclu  dans l'échantillon (probabilité d'inclusion)

$z_i/\pi_i$ s'appelle les valeurs étendues

Cette formule fonctionne pour n'importe quel plan d'échantillonnage avec $\pi_i$ connus

Pour un SIR, la probabilité qu'un site soit choisi pour un tirage vaut $1/N$

avec $n$ tirage, elle vaut $\pi_i = n/N$

Le total peut donc être estimé par $N/n\sum_{i=1}^n{z_i } = N \hat{z}$




### La moyenne pour la population discrète finie

Avec le plan aléatoire simple, le calcul de la moyenne est très simple

```{r}
# simulation du terrain
terrain2 <- over(MonEch,champSP)

MoyEst <- mean(terrain2$sim1)

MoyEst
```

A comparer avec la moyenne de la population $`r Moy`$

### La variance spatiale et variance d'échantillonnage 


Ne confondez pas la variance spatiale et la variance d'échantillonnage !

* La variance spatiale (variance de population) est une  caractéristique de la population
* La variance d'échantillonnage est une caractéristique d'une stratégie d'échantillonnage,
c'est-à-dire une combinaison d'un plan d'échantillonnage et d'un estimateur


Son estimation dans le cas d'un SIR pour une population dite infinie

$\hat{V}(\hat{ \overline{z} } )  = \frac{\hat{S^2}(z) } {n}$

soit 

$\hat{V}(\hat{ \overline{z} } )  = \frac{1}  {(n(n-1))} \sum_{i=1}^n (z_i - \hat{ \overline{z} })$


Mais l'estimateur peut être utilisé pour les populations finie


$\hat{V}(\hat{ \overline{z} } )  =  (1 - \frac{n}N) \frac{\hat{S^2}(z) } {n}$

avec
$(1 - \frac{n}N)$  correspondant à la correction pour les populations finies

```{r}
# Variance d'échantillonnage de MoyEst
V <- var(terrain2$sim1) / n
```

### l'interval de confiance

Le calcul de l'interval de confiance sur la moyenne nécessite de faire une hypothèse sur la distribution de $\hat{ \overline{z} }$

* Pour le un nombre $n$ grand (>30) et si la distribution de la propirété dans l'espace n'est pas trop asymétrique, l'hypothèse de normalité est réaliste

L'intervalle de confiance à $100(1-\alpha)$ %  est:


$\hat{ \overline{z} }\pm u_{1-\alpha/2}.\sqrt{V(\hat{\overline z}) }$


où  $$u_{1-\alpha/2}$$ est le $(1-\alpha/2)$ quantile de la loi normale $u$.

$n$ is the number of sampling observations to compute the mean, eg $n_h*H$.

* Pour des $n$ petit (<30), la loi de Student est plus adaptée. on obtient:


$\hat{ \overline{z} }\pm t_{1-\alpha/2}^{(n-1)}.\sqrt{V(\hat{t^l}) }$

où  $$t^{(n-1)}_{1-\alpha/2}$$ est le $(1-\alpha/2)$ quantile de la loi de  Student $t$ avec $(n-1)$ degrees of freedom. $n$ is the number of sampling observations to compute the mean, eg $n_h*H$.


Voici comment le mettre en oeuvre dans $`R`$

```{r}
# calcul du quantile
zalpha <- qnorm(p = 1- (0.05/2), mean = 0, sd = 1)
# si n est petit < 30
talpha <- qt(p = 1- (0.05/2) , df = n-1)

# calcul de l'interval de confiance selon les deux lois
IC <- zalpha * sqrt(V)
ICT <- talpha * sqrt(V)

c(IC,ICT)

# comme n< 30, on garde ICT
# Est-ce que la vraie moyenne est dans l'IC student
Moy < MoyEst + ICT
Moy > MoyEst - ICT

2 *ICT

cbind(MoyEst, ICbas = MoyEst - ICT, ICHaut =MoyEst + ICT, Moy)

```


Simulations d'un interval de confiance
-----------

Dans cette partie, nous allons tenter d'appréhender l'incertitude de l'estimation de l'indicateur  à travers la réalisation de plusieurs échantillonnages simulés de 20 échantillons.

Pour cela, nous tirons au hasard 20 points 10000 fois et nous effectuons la jointure spatiale avec la couche SIG supposée représenter la réalité terrain.

```{r}
n = 20
rep = 10000

N = n * rep
MonEch <- spsample( champSP , N , type = "random")

# on récupère les valeurs de carbone
terrainSimul <- over(MonEch,champSP)

```

On calcule ensuite, par réplication, les estimations de la moyenne, de la variance d'échantillonnage et de l'intervace de confiance de la moyenne.

```{r}
terrainSimul$id <- rep(1:rep,n)

MesMoys <- aggregate(terrainSimul$sim1,
                     by = list(terrainSimul$id),
                     FUN = mean)

MesVarsEch <- aggregate(terrainSimul$sim1,
                        by = list(terrainSimul$id),
                        FUN = var) 

MesVarsEch$x <- MesVarsEch$x / 20

MesStats <- cbind.data.frame(MesMoys,MesVarsEch$x)
colnames(MesStats) <- c('Group','Moy','VarEch')

MesStats$UCI <- MesStats$Moy + talpha * sqrt(MesStats$VarEch)
MesStats$LCI <- MesStats$Moy - talpha * sqrt(MesStats$VarEch)
```


Pour se rendre compte de l'intervalle de confiance à 95 %, nous représentons sur le graphique suivant pour les 100 premiers tirages, les estimations de la moyenne, et de son intervalle. Nous représentons également la vraie moyenne calculée sur tous les pixels: $`r Moy`$



```{r IC50, fig.cap='Représentation de l\'intervalle de confiance à 95 % et de la vraie moyenne en rouge pour chaque simulation', out.width='110%', fig.asp=.75, fig.align='center'}
ggplot(MesStats[ MesStats$Group %in% 1:100  , ]) + 
  geom_pointrange(size = 0.62, 
                aes(x = Group, ymin = UCI, ymax = LCI, y = Moy)) +
  geom_abline(intercept =  Moy, slope = 0, color = "red")
```


Enfin, il est possible de calculer sur l'ensemble des réalisations, le nombre de fois que la vraie moyenne tombe en dehors de l'intervalle de confiance. Ce qui donne :

```{r }
MesStats$test <- ifelse(Moy > MesStats$LCI,
                        ifelse(Moy< MesStats$UCI,
                               1,0),
                        0)

100* sum(MesStats$test)/rep
```

OUI, 95 % comme attendu !
